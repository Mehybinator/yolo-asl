                  epoch,             train/loss,  metrics/accuracy_top1,  metrics/accuracy_top5,               val/loss,                 lr/pg0,                 lr/pg1,                 lr/pg2
                      1,                 1.6989,                0.92355,                0.99753,                 1.7182,             0.00023666,             0.00023666,             0.00023666
                      2,                0.42572,                0.97041,                      1,                 1.5937,             0.00045117,             0.00045117,             0.00045117
                      3,                 0.3218,                0.91985,                0.99877,                 1.6414,             0.00064211,             0.00064211,             0.00064211
                      4,                0.26331,                0.96671,                      1,                 1.5873,             0.00060797,             0.00060797,             0.00060797
                      5,                 0.2334,                0.97534,                      1,                 1.5773,             0.00057263,             0.00057263,             0.00057263
                      6,                0.17177,                0.97534,                      1,                  1.575,             0.00053728,             0.00053728,             0.00053728
                      7,                0.18752,                0.97287,                      1,                 1.5738,             0.00050194,             0.00050194,             0.00050194
                      8,                0.16833,                0.98274,                      1,                 1.5649,              0.0004666,              0.0004666,              0.0004666
                      9,                0.13034,                0.98274,                      1,                 1.5623,             0.00043126,             0.00043126,             0.00043126
                     10,                0.11152,                0.98644,                      1,                 1.5611,             0.00039591,             0.00039591,             0.00039591
                     11,                0.09964,                0.97904,                      1,                 1.5674,             0.00036057,             0.00036057,             0.00036057
                     12,                0.10564,                0.98644,                      1,                  1.558,             0.00032523,             0.00032523,             0.00032523
                     13,                0.08609,                0.98274,                      1,                 1.5581,             0.00028988,             0.00028988,             0.00028988
                     14,                0.08728,                0.98274,                      1,                 1.5598,             0.00025454,             0.00025454,             0.00025454
                     15,                0.08273,                 0.9852,                      1,                 1.5575,              0.0002192,              0.0002192,              0.0002192
                     16,                 0.0788,                0.98644,                      1,                 1.5572,             0.00018385,             0.00018385,             0.00018385
                     17,                0.06476,                 0.9852,                      1,                  1.559,             0.00014851,             0.00014851,             0.00014851
                     18,                0.06988,                 0.9852,                      1,                 1.5561,             0.00011317,             0.00011317,             0.00011317
                     19,                0.05536,                0.98767,                      1,                 1.5563,             7.7826e-05,             7.7826e-05,             7.7826e-05
                     20,                0.05094,                0.98767,                      1,                 1.5563,             4.2483e-05,             4.2483e-05,             4.2483e-05
